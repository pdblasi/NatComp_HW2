% !TEX root = BioInspired.tex

\chapter{Evolutionary Algorithms - Text Chapter 3}

\section{Problem 1}
\textbf{Implement the various hill-climbing procedures and the simulated annealing algorithm to solve the problem exemplified in Equation~\ref{eqn_1.1}. Use a real-valued representation scheme for the candidate solutions (variable x).} \newline \\
\textbf{By comparing the performance of the algorithms, what can you conclude?} \newline \\
\textbf{For the simple hill-climbing try different initial configurations as attempts at finding the global optimum. Was this algorithm successful?} \newline \\
\textbf{Discuss the sensitivity of all the algorithms in relation to their input parameters.} \newline \\
\begin{equation}\label{eqn_1.1}
g(x) = 2^{-2((x - 0.1) / 0.9)^2} * \sin(5 \pi x)^6
\end{equation}

Simple Hill Climb: \\

In the simple hill climb algorithm, a point is randomly selected in the search space, evaluated, slightly perturbed and re-evaluated until either a max iteration value or non-signifacant change happens.  This algorithm easily finds local maximums or minimums but can miss the global extrema since there is no way to `escape' a local extrema.\\

Iterated Hill Climb: \\

The iterated hill climb algorithm repeats the simple hill climb for a specified number of loops, with random starting points each time, and keeps track of the best solution. Since this simply reruns simple hill climb over and over with different starting points, local extremas can be `escaped' or `ignored' and the global extrema found. \\

Stochastic Hill Climb: \\

The stochastic hill climb is quite similar to the simple hill climb, with one change that makes a significant difference. When the point is perturbed, it is perturbed randomly and its acceptance as a new point is probabilistically determined with Equation~\ref{eqn_1.2} The value of T plays an important part in this equation. T determines the decay of the exponential function. In plain words, T determines how important the relative difference between the evaluation of x and x' is. A large T will make the search very similar to a random search and does not provide consistent results. When T is small, local extremas can be escaped and global extremas found with fairly consistent results.  \\

Simulated Annealing: \\

The simulated annealing algorithm is very similar in concept to the stochastic hill climbing method. The difference is in the T value, which instead of being set, starts at a large value and becomes much smaller over the algorithm's execution. This allows the algorithm to start out as nearly random and lets it more fully cover the search space. As the algorithm continues, the probability of it jumping out of the current extrema gets smaller. This combination gets the algorithm to completely cover the search space and then concentrate itself on the global extrema instead of the local ones.

\begin{equation}\label{eqn_1.2}
P = 1 / ( 1 + exp[ ( eval(x) - eval(x') ) / T ] )
\end{equation}

A few sample runs of the various hill climb algorthims can be found in Figure~\ref{hill_climb}.


\begin{figure}[tbh]
\begin{center}
\includegraphics[width=0.47\textwidth]{HillClimb}
\hspace{20pt}
\includegraphics[width=0.47\textwidth]{SimulatedAnnealing}
\end{center}
\caption{Sample Hill Climb Algorithms Answers \label{hill_climb} }
\end{figure}


\newpage
\section{Problem 2}
\textbf{Implement and apply the hill-climbing, simulated annealing, and genetic algorithms to maximize function $g(x)$ used in the previous exercise assuming a bitstring representation.} \newline \\
\textbf{Tip: The pertubation to be introduced in the candidate solutions for the hill-climbing and simulated annealing algorithms may be implemented similarly to the point mutation in genetic algorithms. Note that in this case, no concern is required about the domain of x, because the binary representation already accounts for it.} \newline \\
\textbf{Discuss the performance of the algorithms and asses their sensitivity in relation to the input parameters.}

\subsection{Summary}
Expanding on the evaluations in the previous problem we add a simple genetic algorithm to the mix. As mentioned, many of the solutions above can find themselves caught in a local extrema for many optimization problems. The genetic algorithm (granted a large enough initial population) avoids this problem by sampling a larger area of the search space.

\subsection{Implementation}
The code can be found in Listing~\ref{Problem2EA.py}.

\subsubsection{Encoding}
For the gene encoding, we used an unsigned 16 bit integer. This gave us an easy way to store 16 bits. Since we know the domain of the problem is restricted to $[0, 1]$ decoding the genotype into a phenotype was done by dividing the integer value of the bit string by the maximum value of a 16 bit integer (65535). Because the values are stored as integers, we can use numpy's random\_integers function to initialize the population.

\subsubsection{Crossover \& Mutation}
Crossover and mutation were handled by binary operations. Binary masks were stored in lists for each operator and a random index into those lists was generated to pick the mask used.

For mutation the individual was XOR'd with the mask to flip the proper bit. For crossover one parent was AND'd with the chosen mask and the other was AND'd with that masks negation. These values were then OR'd together to make the child individual.

\subsubsection{Selection}
Since our fitness values were simply the y values of the function and maximizing the function was the goal, a simple roulette selection method was chosen.

To avoid having to mess with the list of fitness values, an unused index list is created, and this is what the indexes are chosen from. Iterating through the unused list we add the value at that list to a variable until it is greater than or equal to a random value between 0 and the summation.

Between choosing each index the value at the chosen index is subtracted from the sum to avoid having to sum the unused values again. Unfortunately, since this uses floating point calculations it occasionally didn't reach the sum before the algorithm ran out of indexes. We fixed this problem by defaulting to the last index if the sum hasn't been reached by that point.

\subsection{Analysis}
Through multiple runs with different parameters, it was found that a genetic algorithm could solve this problem consistently with an initial population as low as 10 individuals in 250 iterations. The fastest consistent solution came from runs with around 100 individuals and 100 iterations. If more iterations were run it was able to get more precise, giving an answer of .0999923704891 for a max of .999999956813. Taking into account that the encoding isn't perfect this probably means we have the global max at .1 with a value of 1.

In comparison with the other methods summarized in the previous problem the genetic algorithm is rather slow. But it has a much wider range of effective input parameters and when compared to a simple hill climbing algorithm gets the right solution much more often.


\newpage
\section{Problem 7}
\textbf{Determine, using genetic programming (GP), the computer program (S-expression) that produces exactly the outputs presented in Table 3.3 for each value of x. The following hypotheses are given:}
\begin{itemize}
\item \textbf{Use only functions with two arguments (binary trees).}
\item \textbf{Largest depth allowed for each tree: 4}
\item \textbf{Function set: F = {+, *}}
\item \textbf{Terminal set: T = {0, 1, 2, 3, 4, 5, x}}
\end{itemize}
\centerline{\begin{tabular}{| c | c |}
\hline
x & Program output \\
\hline
-10 & 153 \\
\hline
-9 & 120 \\
\hline
-8 & 91 \\
\hline
-7 & 66 \\
\hline
-6 & 45 \\
\hline
-5 & 28 \\
\hline
-4 & 15 \\
\hline
-3 & 6 \\
\hline
-2 & 1 \\
\hline
-1 & 0 \\
\hline
0 & 3 \\
\hline
1 & 10 \\
\hline
2 & 21 \\
\hline
3 & 36 \\
\hline
4 & 55 \\
\hline
5 & 78 \\
\hline
6 & 105 \\
\hline
7 & 136 \\
\hline
8 & 171 \\
\hline
9 & 210 \\
\hline
10 & 253 \\
\hline
\end{tabular}}

\subsubsection{Summary}
For this problem we originally intended to use BNF encoding and the related crossover and mutation operators with it. We were not able to get BNF encoding to work well as we were unsure of how to validate a string of integers as being a valid string. We then moved to an adapted simple genetic algorithm that worked on a prefix format equation. This encoding made validating the string and ensuring that the resulting tree was limited to a depth of four much easier.

\subsubsection{Encoding}
As stated above the encoding is as a prefix formatted equation. This format is easy to do crossover with (when we set the format of the equation in stone), but mutation has to check for two different cases of mutation. One for operators and one for terminals. The operators and terminals are given from the problem and explicitly stated below. \\
\centerline{
\begin{tabular}{| c | c |}
\hline
Operators & Terminals \\
\hline
	& 0 \\
	& 1 \\
+	& 2 \\ 
*	& 3 \\
	& 4 \\
	& 5 \\
	& x \\
\hline
\end{tabular}} \\

To simplify the encoding process, we started with a default encoding and then used the mutation operator to randomize the initial population. The default encoding can be seen below. \\

\centerline{+ + + 0 0 + 0 0 + + 0 0 + 0 0} \hfill \\

This evaluates to the following tree:

\centerline{
\begin{minipage}{.5\linewidth}
\centerline{+ } \hfill \\
\centerline{\hfill + \hfill + \hfill } \hfill \\
\centerline{\hfill + \hfill + \hfill + \hfill + \hfill } \hfill \\
\centerline{\hfill 0 \hfill 0 \hfill 0 \hfill 0 \hfill  0 \hfill 0 \hfill 0 \hfill 0 \hfill} \hfill \\
\end{minipage}}

As you can see, this is not a particularly useful individual, so we copy it and randomize it through mutation to sample the search space.

\subsubsection{Crossover \& Mutation}
Crossover was even simpler in this problem than in the previous. Our prefix equation was stored as a list of strings, so we split the mother and father lists at a random crossover point and recombined them into a child.

Mutation was more complicated in this problem but only marginally so. The complication was that there are two parts to the individuals using our encoding. There were the operators and the terminals. Since the locations of these are fixed, we stored the locations of each in a separate list, and if our randomly selected mutation index is in the operator index list we replace the value with a random operator. If the mutation index is in the terminals index list we replace the value with a random terminal.

\subsubsection{Selection}
The roulette selection operator from the previous problem was reused. To make it work properly, the evaluation function had to be modified significantly. Our first instinct was to add up the difference between the expected and found values. This was easy to implement so we went with it, but this evaluation function does the exact opposite of what we want. It creates high values for less fit individuals. We solved this by finding the maximum value and then replacing every individual's fitness with $(max - fitness) / max$. This normalized the values between 0 and 1 and made them be the proper fitness relative to each other.

\subsubsection{Analysis}
The hardest part of this problem was to choose a good representation for the individuals. The prefix notation worked well and forcing a format that expanded to a full depth four tree simplified a lot of the process.

When using a population of 250 and up to 1000 iterations (up to because we can short circuit the process if we find a perfect solution) we calculated a \%100 match 100 times out of 100. The full list of these can be found in Appendix~\ref{results.out}.

Because we didn't want to fully analyze 100 different prefix notation equations, we randomly picked 10 to evaluate. These are listed below.

\begin{center}
\begin{tabular}{| c | c | c |}
\hline
Solution & Prefix & Simplified \\ \hline \hline
52 & \hspace{5pt} $+\;\;+\;\;*\;\;x\;\;x\;\;*\;\;x\;\;x\;\;+\;\;*\;\;x\;\;4\;\;+\;\;3\;\;x$ \hspace{5pt} & \hspace{5pt} $2x^2 + 5x + 3$ \hspace{5pt} \\ \hline
81 & \hspace{5pt} $+\;\;*\;\;+\;\;0\;\;x\;\;+\;\;x\;\;x\;\;+\;\;+\;\;2\;\;1\;\;*\;\;5\;\;x$ \hspace{5pt} & \hspace{5pt} $2x^2 + 5x + 3$ \hspace{5pt} \\ \hline
49 & \hspace{5pt} $+\;\;+\;\;+\;\;3\;\;x\;\;*\;\;x\;\;x\;\;*\;\;+\;\;x\;\;0\;\;+\;\;x\;\;4$ \hspace{5pt} & \hspace{5pt} $2x^2 + 5x + 3$ \hspace{5pt} \\ \hline
93 & \hspace{5pt} $*\;\;+\;\;+\;\;x\;\;0\;\;+\;\;0\;\;1\;\;+\;\;+\;\;2\;\;1\;\;*\;\;2\;\;x$ \hspace{5pt} & \hspace{5pt} $2x^2 + 5x + 3$ \hspace{5pt} \\ \hline
47 & \hspace{5pt} $+\;\;+\;\;*\;\;x\;\;5\;\;+\;\;3\;\;0\;\;*\;\;+\;\;0\;\;2\;\;*\;\;x\;\;x$ \hspace{5pt} & \hspace{5pt} $2x^2 + 5x + 3$ \hspace{5pt} \\ \hline
26 & \hspace{5pt} $*\;\;+\;\;+\;\;x\;\;2\;\;+\;\;x\;\;1\;\;+\;\;+\;\;x\;\;0\;\;+\;\;1\;\;0$ \hspace{5pt} & \hspace{5pt} $2x^2 + 5x + 3$ \hspace{5pt} \\ \hline
62 & \hspace{5pt} $+\;\;+\;\;*\;\;x\;\;x\;\;+\;\;3\;\;x\;\;+\;\;*\;\;x\;\;4\;\;*\;\;x\;\;x$ \hspace{5pt} & \hspace{5pt} $2x^2 + 5x + 3$ \hspace{5pt}  \\ \hline
68 & \hspace{5pt} $*\;\;+\;\;+\;\;x\;\;x\;\;+\;\;0\;\;3\;\;+\;\;*\;\;2\;\;0\;\;+\;\;1\;\;x$ \hspace{5pt} & \hspace{5pt} $2x^2 + 5x + 3$ \hspace{5pt}  \\ \hline
42 & \hspace{5pt} $*\;\;+\;\;*\;\;0\;\;3\;\;+\;\;x\;\;1\;\;+\;\;+\;\;3\;\;x\;\;+\;\;0\;\;x$ \hspace{5pt} & \hspace{5pt} $2x^2 + 5x + 3$ \hspace{5pt}  \\ \hline
29 & \hspace{5pt} $+\;\;*\;\;+\;\;2\;\;x\;\;+\;\;x\;\;x\;\;+\;\;+\;\;x\;\;3\;\;+\;\;0\;\;0$ \hspace{5pt} & \hspace{5pt} $2x^2 + 5x + 3$ \hspace{5pt}  \\ \hline
\end{tabular}
\end{center}

Summarizing these, it looks like the equation is

\begin{equation}\label{p7_solution}
2x^2 + 5x + 3
\end{equation}